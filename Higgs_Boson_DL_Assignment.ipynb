{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a400a40",
   "metadata": {},
   "source": [
    "# Deep Learning Module Project â€” Higgs Boson Signal Classification\n",
    "\n",
    "## Objective\n",
    "\n",
    "Design, train, and evaluate a deep learning model using tabular data from the Kaggle Higgs Boson Machine Learning Challenge.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Data Preparation\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"training.csv\")  # Replace with your actual file path\n",
    "\n",
    "# Drop non-feature columns if any\n",
    "if 'EventId' in df.columns:\n",
    "    df.drop(['EventId', 'Weight'], axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "# Replace -999.0 with NaN and fill with mean\n",
    "df.replace(-999.0, np.nan, inplace=True)\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('Label', axis=1)\n",
    "y = df['Label'].map({'s': 1, 'b': 0})\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train/Val/Test split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Model Building (Deep Learning)\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(patience=3, factor=0.5)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=256,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Model Evaluation\n",
    "\n",
    "```python\n",
    "# Plot accuracy/loss\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train')\n",
    "plt.plot(history.history['val_accuracy'], label='Val')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train')\n",
    "plt.plot(history.history['val_loss'], label='Val')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc = roc_auc_score(y_test, y_pred_probs)\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC AUC: {roc:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_probs)\n",
    "plt.plot(fpr, tpr, label=f'AUC = {roc:.2f}')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Baseline Comparison with XGBoost\n",
    "\n",
    "```python\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "xgb_prob = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, xgb_pred))\n",
    "print(\"XGBoost F1 Score:\", f1_score(y_test, xgb_pred))\n",
    "print(\"XGBoost ROC AUC:\", roc_auc_score(y_test, xgb_prob))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Reflection\n",
    "\n",
    "**Q: How did model depth and activation affect performance?**  \n",
    "Deeper models with ReLU performed better up to a point, but introduced overfitting if not regularized.\n",
    "\n",
    "**Q: What helped mitigate overfitting?**  \n",
    "Dropout, BatchNormalization, and EarlyStopping helped prevent overfitting.\n",
    "\n",
    "**Q: How did the learning rate and optimizer affect convergence?**  \n",
    "Adam showed faster convergence; tuning `ReduceLROnPlateau` improved stability.\n",
    "\n",
    "**Q: What would you improve with more time or compute?**  \n",
    "I would tune hyperparameters with Keras Tuner, perform cross-validation, and try ensemble techniques.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
